{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af79a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser.ipynb  README.md  WNdb-3.0.tar.gz  dict\tparsers\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bb6f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndexDF(filePath):\n",
    "    with open(filePath) as f:\n",
    "        Indexdump = f.readlines()\n",
    "    indexLines = []\n",
    "    for i in Indexdump:\n",
    "        if i[0] == \" \" or i[0] == \".\":\n",
    "            continue\n",
    "        else:\n",
    "            indexLines.append(i.strip())\n",
    "    for i in range(len(indexLines)):\n",
    "        splitLine = indexLines[i].split()\n",
    "        if (len(splitLine) == 8):\n",
    "            indexLines[i] = splitLine\n",
    "            continue\n",
    "        ls = []\n",
    "        ls.extend(splitLine[0:4])\n",
    "        p_cnt = int(ls[-1])\n",
    "        ls.append(splitLine[4:4 + p_cnt])\n",
    "        sense_cntIndex = 4 + p_cnt\n",
    "        ls.append(splitLine[sense_cntIndex])\n",
    "        tagsense_cntIndex = sense_cntIndex + 1\n",
    "        ls.append(splitLine[tagsense_cntIndex])\n",
    "        remainingStartIndex = tagsense_cntIndex + 1\n",
    "        ls.append(splitLine[remainingStartIndex:])\n",
    "        indexLines[i] = ls\n",
    "    df = pd.DataFrame(indexLines, columns = ['lemma', 'pos', 'synset_cnt', 'p_cnt', 'ptr_symbol', 'sense_cnt', 'tagsense_cnt', 'synset_offset'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "af8ea10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataDF(filePath, Isverb=False):\n",
    "    with open(filePath) as f:\n",
    "        Datadump = f.readlines()\n",
    "    dataLines = []\n",
    "    for i in Datadump:\n",
    "        if i[0] == \" \" or i[0] == \".\":\n",
    "            continue\n",
    "        else:\n",
    "            dataLines.append(i.strip())\n",
    "    for i in range(len(dataLines)):\n",
    "        splitLine = dataLines[i].split()\n",
    "        ls = []\n",
    "        ls.extend(splitLine[:4])\n",
    "        wordCount = int(ls[-1], 16)\n",
    "        currIndex = 4\n",
    "        ls_words_and_lexids = []\n",
    "        for j in range(wordCount):\n",
    "            ls_words_and_lexids.append([splitLine[currIndex],splitLine[currIndex+1]])\n",
    "            currIndex += 2\n",
    "        ls.append(ls_words_and_lexids)\n",
    "        p_cnt = splitLine[currIndex]\n",
    "        ls.append(p_cnt)\n",
    "        currIndex += 1\n",
    "        ptrList = []\n",
    "        for j in range(int(p_cnt)):\n",
    "            ptrList.append([splitLine[currIndex],splitLine[currIndex+1],splitLine[currIndex+2],splitLine[currIndex+3]])\n",
    "            currIndex += 4\n",
    "        ls.append(ptrList)\n",
    "        if (Isverb):\n",
    "            f_cnt = int(splitLine[currIndex])\n",
    "            currIndex += 2\n",
    "            ls.append(f_cnt)\n",
    "            ls_fnum_wnum = []\n",
    "            for j in range(f_cnt):\n",
    "                ls_fnum_wnum.append([splitLine[currIndex],splitLine[currIndex+1]])\n",
    "                currIndex += 3\n",
    "            ls.append(ls_fnum_wnum)\n",
    "        ls.append(\" \".join(splitLine[currIndex:]))\n",
    "        dataLines[i] = ls\n",
    "    if (Isverb):\n",
    "        df = pd.DataFrame(dataLines, columns = ['synset_offset', 'lex_filenum', 'ss_type', 'w_cnt', 'word with lex_id', 'p_cnt', 'ptr', 'f_cnt', 'frame', 'gloss'])\n",
    "    else:\n",
    "        df = pd.DataFrame(dataLines, columns = ['synset_offset', 'lex_filenum', 'ss_type', 'w_cnt', 'word with lex_id', 'p_cnt', 'ptr', 'gloss'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7ffa8497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synset_offset</th>\n",
       "      <th>lex_filenum</th>\n",
       "      <th>ss_type</th>\n",
       "      <th>w_cnt</th>\n",
       "      <th>word with lex_id</th>\n",
       "      <th>p_cnt</th>\n",
       "      <th>ptr</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001740</td>\n",
       "      <td>00</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[able, 0]]</td>\n",
       "      <td>005</td>\n",
       "      <td>[[=, 05200169, n, 0000], [=, 05616246, n, 0000...</td>\n",
       "      <td>| (usually followed by `to') having the necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002098</td>\n",
       "      <td>00</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[unable, 0]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[=, 05200169, n, 0000], [!, 00001740, a, 0101]]</td>\n",
       "      <td>| (usually followed by `to') not having the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002312</td>\n",
       "      <td>00</td>\n",
       "      <td>a</td>\n",
       "      <td>02</td>\n",
       "      <td>[[abaxial, 0], [dorsal, 4]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[;c, 06037666, n, 0000], [!, 00002527, a, 0101]]</td>\n",
       "      <td>| facing away from the axis of an organ or org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002527</td>\n",
       "      <td>00</td>\n",
       "      <td>a</td>\n",
       "      <td>02</td>\n",
       "      <td>[[adaxial, 0], [ventral, 4]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[;c, 06037666, n, 0000], [!, 00002312, a, 0101]]</td>\n",
       "      <td>| nearest to or facing toward the axis of an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002730</td>\n",
       "      <td>00</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[acroscopic, 0]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[;c, 06066555, n, 0000], [!, 00002843, a, 0101]]</td>\n",
       "      <td>| facing or on the side toward the apex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>03154786</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[transpiring, 0]]</td>\n",
       "      <td>001</td>\n",
       "      <td>[[&lt;, 02066757, v, 0101]]</td>\n",
       "      <td>| that is passing through; \"transpiring gas\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>03154886</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[sought, 0]]</td>\n",
       "      <td>001</td>\n",
       "      <td>[[&lt;, 01315613, v, 0102]]</td>\n",
       "      <td>| that is looked for; \"the long sought relatives\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>03154986</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[closed-captioned, 0]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[;c, 06277280, n, 0000], [&lt;, 02323870, v, 0101]]</td>\n",
       "      <td>| broadcast with captions that are seen only o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18154</th>\n",
       "      <td>03155193</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[saponified, 0]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[!, 03155306, a, 0101], [&lt;, 00538571, v, 0101]]</td>\n",
       "      <td>| converted into soap; \"saponified oils\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18155</th>\n",
       "      <td>03155306</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>01</td>\n",
       "      <td>[[unsaponified, 0]]</td>\n",
       "      <td>002</td>\n",
       "      <td>[[!, 03155193, a, 0101], [&lt;, 00538571, v, 0101]]</td>\n",
       "      <td>| not converted into soap; \"unsaponified fat\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      synset_offset lex_filenum ss_type w_cnt              word with lex_id  \\\n",
       "0          00001740          00       a    01                   [[able, 0]]   \n",
       "1          00002098          00       a    01                 [[unable, 0]]   \n",
       "2          00002312          00       a    02   [[abaxial, 0], [dorsal, 4]]   \n",
       "3          00002527          00       a    02  [[adaxial, 0], [ventral, 4]]   \n",
       "4          00002730          00       a    01             [[acroscopic, 0]]   \n",
       "...             ...         ...     ...   ...                           ...   \n",
       "18151      03154786          44       a    01            [[transpiring, 0]]   \n",
       "18152      03154886          44       a    01                 [[sought, 0]]   \n",
       "18153      03154986          44       a    01       [[closed-captioned, 0]]   \n",
       "18154      03155193          44       a    01             [[saponified, 0]]   \n",
       "18155      03155306          44       a    01           [[unsaponified, 0]]   \n",
       "\n",
       "      p_cnt                                                ptr  \\\n",
       "0       005  [[=, 05200169, n, 0000], [=, 05616246, n, 0000...   \n",
       "1       002   [[=, 05200169, n, 0000], [!, 00001740, a, 0101]]   \n",
       "2       002  [[;c, 06037666, n, 0000], [!, 00002527, a, 0101]]   \n",
       "3       002  [[;c, 06037666, n, 0000], [!, 00002312, a, 0101]]   \n",
       "4       002  [[;c, 06066555, n, 0000], [!, 00002843, a, 0101]]   \n",
       "...     ...                                                ...   \n",
       "18151   001                           [[<, 02066757, v, 0101]]   \n",
       "18152   001                           [[<, 01315613, v, 0102]]   \n",
       "18153   002  [[;c, 06277280, n, 0000], [<, 02323870, v, 0101]]   \n",
       "18154   002   [[!, 03155306, a, 0101], [<, 00538571, v, 0101]]   \n",
       "18155   002   [[!, 03155193, a, 0101], [<, 00538571, v, 0101]]   \n",
       "\n",
       "                                                   gloss  \n",
       "0      | (usually followed by `to') having the necess...  \n",
       "1      | (usually followed by `to') not having the ne...  \n",
       "2      | facing away from the axis of an organ or org...  \n",
       "3      | nearest to or facing toward the axis of an o...  \n",
       "4                | facing or on the side toward the apex  \n",
       "...                                                  ...  \n",
       "18151       | that is passing through; \"transpiring gas\"  \n",
       "18152  | that is looked for; \"the long sought relatives\"  \n",
       "18153  | broadcast with captions that are seen only o...  \n",
       "18154           | converted into soap; \"saponified oils\"  \n",
       "18155      | not converted into soap; \"unsaponified fat\"  \n",
       "\n",
       "[18156 rows x 8 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createDataDF('dict/data.adj', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13266d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
